# -*- coding: utf-8 -*-
"""sentiment analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TEZKgUqv0Nk5QKPvteUrHc-gXbJnzUrc
"""

from wordcloud import WordCloud
from sklearn.metrics import accuracy_score,classification_report
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('/content/01-advance.csv')
dataset.head()

dataset.shape

dataset.isnull().sum()

#Selecting Required Columns:
dataset = dataset[['reviews','stars']]

#Review Ratings Distribution:
data = dataset['stars'].value_counts()

sns.barplot(x=data.index, y=data.values)

text = ""
for i in dataset.reviews:
    text += i
print(text)

from nltk.tokenize import word_tokenize

nltk.download("punkt")
words = word_tokenize(text, language="english")
print(words)

print(len(words))

import nltk
from nltk.corpus import stopwords

#nltk.download('stopwords')

stop_words = set(stopwords.words("english"))
print(stop_words)

from wordcloud import WordCloud

wc = WordCloud(background_color="black", max_words=300, stopwords=stop_words, max_font_size=50, random_state=42)

"""Display the wordcloud"""

import matplotlib.pyplot as plt

# Generate and display the word cloud

plt.figure(figsize= (15,15)) # Figure initialization
wc.generate(text) # "Calculation" from the wordcloud
plt.imshow(wc) # Display
plt.show()

tokens = []
def stop_words_filtering(words):
    
    for word in words:
        if word not in stop_words:
            tokens.append(word)
    return tokens


print(stop_words_filtering(words))

print(len(tokens))

train_data=dataset['reviews']
y_target=dataset['stars'].map({1:'Unhappy',2:'Unhappy',3:'Happy',4:'Happy',5:'Happy'})

X_train, X_test, y_train, y_test = train_test_split(train_data, y_target, test_size=0.2)

from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()

X_train = vectorizer.fit_transform(X_train).todense()
X_test = vectorizer.transform(X_test).todense()

clf = GradientBoostingClassifier(
    n_estimators=100, random_state=44
).fit(X_train, y_train)

y_pred = clf.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))

print("Accuracy Train: {}".format(accuracy_score(y_test,y_pred )))

import scikitplot as skplt
skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize=True)
plt.show()

confusion_matrix = pd.crosstab(
    y_test, y_pred, rownames=["Real Class"], colnames=["Predicted Class"]
)
confusion_matrix